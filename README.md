# Compilador-Manchester-Syntax-OWL2

Esse projeto tem como objetivo construir um compilador para reconhecimento da linguagem OWL2 (Web Ontology Language) no formato Manchester Syntax.

# √çndice 

* [Compilador](#Compilador)
* [Analisador l√©xico](#analisador-l√©xico)
* [Analisador sint√°tico](#analisador-sint√°tico)
* [Analisador sem√¢ntico](#analisador-sem√¢ntico)
* [Ply](#Ply)
* [Yacc](#Yacc)
* [Requisitos](#Requisitos/Como-usar)


## Compilador 

Um compilador √© um programa de computador que traduz nossos c√≥digos-fontes, escrito em uma linguagem de programa√ß√£o de alto n√≠vel (como C, Java, Python), para uma linguagem de baixo n√≠vel ou linguagem de m√°quina, que o computador pode entender e executar. 

## Analisador L√©xico

A an√°lise l√©xica √© o est√°gio inicial no planejamento do compilador. Um lexema
√© um agrupamento de caracteres distintos dentro de um conjunto de tokens. A an√°lise l√©xica √© executada para examinar todo o c√≥digo-fonte do desenvolvedor. 

O analisador l√©xico √© utilizado para realizar a varredura do programa em seu c√≥digo-fonte, caractere por caractere, a fim de distingui-los na tabela de s√≠mbolos. Um agrupamento de caracteres que n√£o podem ser scaneados √© considerado um erro l√©xico. 

```
BARBOSA, Cynthia da S.; LENZ, Maikon L.; LACERDA, Paulo S. P√°dua de; et al. Compiladores. Porto Alegre: SAGAH, 2021. E-book. p.57. ISBN 9786556902906.
```
## Analisador Sint√°tico

A an√°lise sint√°tica √© o processo ap√≥s a an√°lise l√©xica de uma compila√ß√£o.
O analisador sint√°tico √© o cora√ß√£o da compila√ß√£o, pois os demais processos p√≥s-an√°lise sint√°tica, como analisador sem√¢ntico e gerador de c√≥digo intermedi√°rio, s√£o guiados pelas a√ß√µes da etapa de an√°lise sint√°tica.


```
BARBOSA, Cynthia da S.; LENZ, Maikon L.; LACERDA, Paulo S. P√°dua de; et al. Compiladores. Porto Alegre: SAGAH, 2021. E-book. p.90. ISBN 9786556902906. 
```

##  Funcionalidades  
   O analisador fornecer√° as seguintes funcionalidades 
   
- **An√°lise Sint√°tica** O analisador sint√°tico verifica a estrutura do c√≥digo e se ele segue a gram√°tica da linguagem inserida.

- **Gera√ß√£o de √Årvore Sint√°tica**  O analisador faz a organiza√ß√£o dos tokens encontrados em uma √°rvore sint√°tica que representa a hierarquia do c√≥digo;

- **Classifica√ß√£o das Classes Ontol√≥gicas** as classifica√ß√µes de classes s√£o divididas em:

      1. Classe primitiva  
           
      2. Classe definida  

      3. Classe com axioma de fechamento  

      4. Classe com descri√ß√µes aninhadas  

      5. Classe enumerada

      6. Aninhada


- **Identifica√ß√£o de Erros Sint√°ticos** se a aplica√ß√£o encontrar alguma estrutura que fuja das regras implementadas ela ir√° retornar um erro referente aquela parte do c√≥digo, referenciando a linha e o Token inesperado, por exemplo:

        Erro Sint√°tico: Linha 401: Token inesperado 'only'
        Erro Sint√°tico: Linha 416: Token inesperado 'Class:'


##  Como Funciona?  

   - **Entrada:**  O analisador recebe um conjunto de lexemas a partir do arquivo .txt selecionado.

   - **Processamento:** Se a sintaxe estiver correta, o analisador construir√° uma √°rvore sint√°tica estruturada com base no conjunto de lexemas lidos.

   - **Classifica√ß√£o:**  As classes s√£o definidas conforme a estrutura analisada.

   - **Sa√≠da:** O analisador retorna a estrutura sint√°tica processada e os erros sint√°ticos encontrados, exibindo-os em seus respectivos campos.




## Exemplos de Ontologias Compat√≠veis e suas Respectivas Sa√≠das

- **Classes Primitivas**  √© uma classe cujos indiv√≠duos podem herdar suas propriedades, podendo ou n√£o vir seguidos de DisjointClasses e Individuals, que representam classes disjuntas e indiv√≠duos respectivamente em suas descri√ß√µes

   üîπ Entrada:
   
         Class: Pizza‚Äã ‚Äã      
         SubClassOf:
         hasBase some PizzaBase,
         hasCaloricContent some xsd:integer
         
         DisjointClasses:
         PizzaBase, PizzaTopping
         
         Individuals:
         CustomPizza1,
         CustomPizza2
  
   üîπ Sa√≠da:

- **Classes Definidas**  √© uma classe que cont√©m condi√ß√µes necess√°rias e suficientes em sua
descri√ß√£o, ou seja , a classe CheesyPizza √© equivalente a Pizza e cont√©m hasTopping com uma quatidade "some" CheeseTopping. Como na primitiva a se√ß√£o DisjointClasses e Individuals s√£o opcionais;
    
  üîπ Entrada:
    
    
         Class: CheesyPizza
         EquivalentTo:
         Pizza
         and (hasTopping some CheeseTopping)

         DisjointClasses:
         PizzaBase, PizzaTopping
         
         Individuals:
         CheesyPizza1

  üîπ Sa√≠da:

 - **Classes com Axiomas de Fechamento**  Restringe as rela√ß√µes entre classes com suas propriedades ou respectivas express√µes para que sejam definidas como axiomas de fechamento 
        
     üîπ Entrada:
     
         
         Class: MargheritaPizza
         SubClassOf:
         NamedPizza,
         hasTopping some MozzarellaTopping,
         hasTopping some TomatoTopping,
         hasTopping only (MozzarellaTopping or TomatoTopping)

   üîπSa√≠da:
   

- **Classes Cobertas**  S√£o definidas por uma classe como sendo a superposi√ß√£o de suas classes filhas

  üîπ Entrada:
  
         Class: Spiciness
         EquivalentTo: Hot or Medium or Mild
  
   üîπSa√≠da:

- **Classes Enumeradas**  A classe √© enumerada se ela for definida a partir de suas inst√¢ncias

   üîπ Entrada:
  
         Class: Spiciness
         EquivalentTo: {Hot1, Medium1, Mild1}

   üîπSa√≠da:

- **Classes Aninhadas**  A classe √© definida a partir da tripla composta de propriedade, quantificador e outra classe

   üîπ Entrada:

         Class: SpicyPizza
         EquivalentTo:
         Pizza
         and (hasTopping some (hasSpiciness value Hot))

   üîπSa√≠da:


## Analisador Sem√¢ntico

O compilador verifica se o c√≥digo faz sentido, ou seja, se as opera√ß√µes s√£o v√°lidas de acordo com as regras da linguagem, como tipos de dados compat√≠veis ou vari√°veis declaradas corretamente.

## Ply

### Introdu√ß√£o 

PLY √© uma implementa√ß√£o Python pura das populares ferramentas de constru√ß√£o de compiladores lex e yacc. O principal objetivo do PLY √© permanecer razoavelmente fiel √† maneira como as ferramentas tradicionais lex/yacc funcionam. Isso inclui suporte √† an√°lise sint√°tica LALR(1), bem como fornecer valida√ß√£o de entrada extensiva, relat√≥rios de erros e diagn√≥sticos. Portanto, se voc√™ usou yacc em outra linguagem de programa√ß√£o, deve ser relativamente simples usar o PLY.

### Lex e Yacc

PLY consiste em dois m√≥dulos separados; lex.py e yacc.py , ambos encontrados em um pacote Python chamado ply . O m√≥dulo lex.py √© usado para quebrar o texto de entrada em uma cole√ß√£o de tokens especificados por uma cole√ß√£o de regras de express√£o regular. yacc.py √© usado para reconhecer a sintaxe da linguagem que foi especificada na forma de uma gram√°tica livre de contexto.

### Lex 

lex.py √© usado para tokenizar uma string de entrada. Por exemplo, suponha que voc√™ esteja escrevendo uma linguagem de programa√ß√£o e um usu√°rio forneceu a seguinte string de entrada:

```
x = 3 + 42 * (s - t)
```
Um tokenizador divide a string em tokens individuais

```
'x','=', '3', '+', '42', '*', '(', 's', '-', 't', ')'
```
Tokens geralmente s√£o definidos por nomes e s√£o inseridos junto com os valores na tabela de lexemas . Por exemplo:

```
('ID','x'), ('IGUAL A','='), ('N√öMERO','3'),
('MAIS','+'), ('N√öMERO','42), ('VEZES','*'),
('EPARENTE','('), ('ID','s'), ('MENOS','-'),
('ID','t'), ('DPARENTE',')'
```

### Lex exemplo

```
importar ply.lex como lex

# Lista de nomes de tokens. Isso √© sempre necess√°rio
tokens = (
   'N√öMERO',
   'MAIS',
   'MENOS',
   'TEMPOS',
   'DIVIDIR',
   'EPARENTE',
   'DPARENTE',
)

# Regras de express√£o regular para tokens simples
t_PLUS = r'\+'
t_MENOS = r'-'
t_TEMPOS = r'\*'
t_DIVIDIR = r'/'
t_EPARENTE = r'\('
t_DPARENTE = r'\)'

# Uma regra de express√£o regular com algum c√≥digo de a√ß√£o
def t_NUMBER(t):
    r'\d+'
    t.valor = int(t.valor)    
    retornar t

# Defina uma regra para que possamos rastrear n√∫meros de linha
defini√ß√£o t_newline(t):
    r'\n+'
    t.lexer.lineno += len(t.valor)

# Uma string contendo caracteres ignorados (espa√ßos e tabula√ß√µes)
t_ignore = ' \t'

# Regra de tratamento de erros
defini√ß√£o t_error(t):
    print("Caractere ilegal '%s'" % t.value[0])
    t.lexer.pular(1)

# Construir o analisador l√©xico
lexer = lex.lex()

# Para usar o lexer, primeiro voc√™ precisa aliment√°-lo com algum texto de #
# entrada usando seu m√©todo input() . Depois disso, chamadas repetidas 
# para token() produzem tokens. O c√≥digo a seguir mostra como isso funciona:


# D√™ alguma entrada ao analisador l√©xico
lexer.input(dados)

# Tokenizar
while True:
    tok = lexer.token()
    if not tok: 
        break      # No more input
    print(tok)


```
### Especifica√ß√£o de tokens

Cada token √© especificado escrevendo uma regra de express√£o regular compat√≠vel com o m√≥dulo re do Python . Cada uma dessas regras √© definida fazendo declara√ß√µes com um prefixo especial t_ para indicar que ele define um token. Para tokens simples, a express√£o regular pode ser especificada como strings como esta (nota: strings brutas do Python s√£o usadas, pois s√£o a maneira mais conveniente de escrever strings de express√£o regular):

```
t_PLUS = r'\+'
```

Neste caso, o nome ap√≥s o t_ deve corresponder exatamente a um dos nomes fornecidos em tokens . Se algum tipo de a√ß√£o precisa ser executada, uma regra de token pode ser especificada como uma fun√ß√£o. Por exemplo, esta regra corresponde a n√∫meros e converte a string em um inteiro Python.

```
def t_NUMBER(t):
    r'\d+'
    t.value = int(t.value)
    retornar t
```


### Fichas descartadas
Para descartar um token, como um coment√°rio, basta definir uma regra de token que n√£o retorne nenhum valor. Por exemplo:
```
def t_COMMENT(t):
    r'\#.*'
    pass
    # Nenhum valor de retorno. Token descartado
```

### Tratamento de erros
A fun√ß√£o t_error() √© usada para manipular erros de lexing que ocorrem quando caracteres ilegais s√£o detectados. Nesse caso, o atributo t.value cont√©m o restante da string de entrada que n√£o foi tokenizada. No exemplo, a fun√ß√£o de erro foi definida da seguinte forma:

```
# Regra de tratamento de erros
def t_error(t):
    print("Invalido caractere '%s'" % t.value[0])
    t.lexer.skip(1)
```

## Yacc

O m√≥dulo ply.yacc implementa o componente de an√°lise do PLY. O nome "yacc" significa "Yet Another Compiler Compiler" e √© emprestado da ferramenta Unix de mesmo nome.

### Yacc exemplo

Suponha que voc√™ queira fazer uma gram√°tica para express√µes aritm√©ticas simples: 

```
import ply.yacc as yacc

# Obtenha o mapa de token do lexer. Isso √© obrigat√≥rio. 
de calclex importar tokens 

def p_expression_plus(p):
    'expression : expression PLUS term'
    p[0] = p[1] + p[3]

def p_expression_minus(p):
    'expression : expression MINUS term'
    p[0] = p[1] - p[3]

def p_expression_term(p):
    'expression : term'
    p[0] = p[1]

def p_term_times(p):
    'term : term TIMES factor'
    p[0] = p[1] * p[3]

def p_term_div(p):
    'term : term DIVIDE factor'
    p[0] = p[1] / p[3]

def p_term_factor(p):
    'term : factor'
    p[0] = p[1]

def p_factor_num(p):
    'factor : NUMBER'
    p[0] = p[1]

def p_factor_expr(p):
    'factor : LPAREN expression RPAREN'
    p[0] = p[2]

# Regra de erro para erros de sintaxe 
def p_error(p):
    print("Syntax error in input!")

# Build the parser
parser = yacc.yacc()

while True:
   try:
       s = raw_input('calc > ')
   except EOFError:
       break
   if not s: continue
   result = parser.parse(s)
   print(result)

```

Neste exemplo, cada regra gramatical √© definida por uma fun√ß√£o Python onde a docstring para essa fun√ß√£o cont√©m a especifica√ß√£o gramatical livre de contexto apropriada. As instru√ß√µes que comp√µem o corpo da fun√ß√£o implementam as a√ß√µes sem√¢nticas da regra. Cada fun√ß√£o aceita um √∫nico argumento p que √© uma sequ√™ncia contendo os valores de cada s√≠mbolo gramatical na regra correspondente. Os valores de p[i] s√£o mapeados para s√≠mbolos gramaticais conforme mostrado aqui:

```
    def p_expression_plus(p):
        'expression : expression PLUS term'
        #   ^            ^        ^    ^
        #  p[0]         p[1]     p[2] p[3]

        p[0] = p[1] + p[3]
```

### Combinando fun√ß√µes de regras gramaticais (Rules) 
Quando as regras gramaticais s√£o semelhantes, elas podem ser combinadas em uma √∫nica fun√ß√£o. Por exemplo, considere as duas regras em nosso exemplo anterior:

```
    def p_expression_plus(p):
        'expression : expression PLUS term'
        p[0] = p[1] + p[3]

    def p_expression_minus(t):
        'expression : expression MINUS term'
        p[0] = p[1] - p[3]
```

Em vez de escrever duas fun√ß√µes, voc√™ pode escrever uma √∫nica fun√ß√£o como esta:


```
    def p_expression(p):
        '''expression : expression PLUS term
                    | expression MINUS term'''
        if p[2] == '+':
            p[0] = p[1] + p[3]
        elif p[2] == '-':
            p[0] = p[1] - p[3]
```

### Produ√ß√µes Vazias
yacc.py pode manipular produ√ß√µes vazias definindo uma regra como esta:
```
    def p_empty(p):
        'empty :'
        pass
```
Agora, para usar a produ√ß√£o vazia, basta usar 'empty' como s√≠mbolo. Por exemplo:
```
    def p_optitem(p):
        'optitem : item'
        '        | empty'
        ...
```


### O arquivo parser.out

O yacc.py usa o algoritmo de an√°lise sint√°tica LR(1), que l√™ a entrada da esquerda para a direita e faz uma deriva√ß√£o √† direita. Durante a an√°lise, podem ocorrer conflitos shift/reduce (quando o parser n√£o sabe se deve deslocar ou reduzir) e reduce/reduce (quando h√° m√∫ltiplas op√ß√µes de redu√ß√£o para o mesmo conjunto de tokens). Quando esses conflitos acontecem, o yacc.py gera um arquivo de depura√ß√£o chamado parser.out, que cont√©m informa√ß√µes detalhadas sobre os conflitos, facilitando a depura√ß√£o e o ajuste da gram√°tica.

## Requisitos/Como usar

Para rodar o projeto √© recomendado a utiliza√ß√£o do WSL ou uso direto do Linux, pois a maioria das distros j√° possuem o Python3 instalado.

Link de como instalar o WSL: [Link](https://learn.microsoft.com/pt-br/windows/wsl/install)

### Requisitos obrigat√≥rios

- Python 3.x
- PIP
- PLY (Python Lex-Yacc)

Caso sua Distro n√£o tenha Python por padr√£o:

```
// BASE DEBIAN
sudo apt update
sudo apt install python3

// BASE FEDORA 
sudo dnf install python3

// BASE ARCH
sudo pacman -S python
```

Instale o PIP usando:

```
sudo apt update
sudo apt install python3-pip
```

Instale o venv usando:

```
sudo apt install python3.12-venv
```

Entre na pasta do projeto e execute o seguinte comanda para iniciar ambiente virtual:

```
python3 -m venv nomeDoAmbiente
```

Ative o ambiente virtual:

```
source nomeDoAmbiente/bin/activate
```

Instale o PLY usando o `pip`:

```
pip install ply
```

Instale o Tkinter usando:

```
sudo apt-get install python3-tk
```

### Comandos para rodar o projeto

```
python3 main.py
```

### Ferramentas para rodar e analisar o projeto
- [VS Code](https://code.visualstudio.com/download)  
- Extens√µes para o VS Code
    - [Python](https://marketplace.visualstudio.com/items?itemName=ms-python.python)  
    - [Pylance](https://marketplace.visualstudio.com/items?itemName=ms-python.vscode-pylance)  
    - [Python Debugger](https://marketplace.visualstudio.com/items?itemName=ms-python.debugpy)  
